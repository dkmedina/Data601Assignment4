{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "from scipy.stats import ttest_ind \n",
    "\n",
    "file_path = \"data/Building_Energy_Benchmarking.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Data Shape:\", data.shape)\n",
    "print(\"Columns:\\n\", data.columns)\n",
    "print(\"Data Types:\\n\", data.dtypes)\n",
    "print(\"Number of Missing Values From Each Columns:\\n\", data.isnull().sum())\n",
    "\n",
    "threshold = 0.4 * len(data) # Setting threshold for 40%\n",
    "\n",
    "data_clean1 = data.dropna(axis=1, thresh=threshold) # Dropping columns that exceed the threshhold\n",
    "\n",
    "numerical_columns = data_clean1.select_dtypes(include=['int64', 'float64']).columns #Defining a numerical column\n",
    "\n",
    "for col in numerical_columns:\n",
    "    data_clean1[col].fillna(data_clean1[col].median(), inplace = True)  #Filling numerical columns with median\n",
    "\n",
    "category_columns = data_clean1.select_dtypes(include=['object']).columns #Defining a categorical column\n",
    "\n",
    "for col in category_columns:\n",
    "    data_clean1[col].fillna(data_clean1[col].mode(), inplace= True) #Filling categorical columns with mode\n",
    "\n",
    "def extract_num(column):\n",
    "    return column.str.extract(r\"(\\d+\\.?\\d*)\").astype(float)\n",
    "\n",
    "unit_columns = [col for col in data_clean1.columns if re.search(r\"\\(.*\\)\", col)] #Comprehension to loop through columns in dataset to see if they have () for units\n",
    "\n",
    "for col in unit_columns:\n",
    "    data_clean1[col] = extract_num(data_clean1[col].astype(str)) #Apply regex numerical extraction on columns with units\n",
    "\n",
    "def postal_code_clean(post_code): #Regex to clean postal codes\n",
    "    match = re.match(r\"([A-Za-z]\\d[A-Za-z])\\s?(\\d[A-Za-z]\\d)\", str(post_code))\n",
    "    return match.group(1) + \" \" + match.group(2) if match else np.nan\n",
    "\n",
    "data_clean1[\"Postal Code\"] = data_clean1[\"Postal Code\"].apply(postal_code_clean)\n",
    "\n",
    "def clean_text(column): #Function to clean text in Property Names and Addresses\n",
    "    column = column.str.replace(r\"\\b(calgary|alberta)\\b\", \"\", flags=re.IGNORECASE, regex=True) # Following rows ensure quandrants are upper case and remove Calgary and Alberta from address 1 \n",
    "    column = column.str.replace(r\"\\b(ne|nw|se|sw)\\b\", lambda x: x.group(0).upper(), flags=re.IGNORECASE, regex=True)\n",
    "    column = column.str.title().str.strip()\n",
    "    return column\n",
    "data_clean1[\"Property Name\"] = clean_text(data_clean1[\"Property Name\"].astype(str)) #Applying functions on both columns\n",
    "data_clean1[\"Address 1\"] = clean_text(data_clean1[\"Address 1\"].astype(str))\n",
    "\n",
    "\n",
    "summary = data_clean1.describe()\n",
    "print(\"\\nSummary Statistics:\\n\", summary)\n",
    "\n",
    "energy_use_int_avg = data_clean1.groupby(\"Primary Property Type - Self Selected\")[\"Site EUI (GJ/m²)\"].mean().sort_values(ascending=False)\n",
    "\n",
    "ghg_by_year = data_clean1.groupby(\"Year Ending\")[\"Total GHG Emissions (Metric Tons CO2e)\"].sum()\n",
    "\n",
    "top5_energy = data_clean1.nlargest(5, \"Site Energy Use (GJ)\")\n",
    "\n",
    "def clean_ghg_total(value):\n",
    "    match = re.findall(r\"(\\d+\\.?\\d*)\", str(value))\n",
    "    return float(match[0]) if match else np.nan #Function to clean numerical values with regex \n",
    "\n",
    "data_clean1['Total GHG Emissions (Metric Tons CO2e)'] = data_clean1['Total GHG Emissions (Metric Tons CO2e)'].apply(clean_ghg_total)\n",
    "\n",
    "for name, group in data_clean1.groupby(\"Primary Property Type - Self Selected\"): #IQR detection of outliers in GHG column\n",
    "    Q1 = group[\"Total GHG Emissions (Metric Tons CO2e)\"].quantile(0.25)\n",
    "    Q3 = group[\"Total GHG Emissions (Metric Tons CO2e)\"].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = (group[\"Total GHG Emissions (Metric Tons CO2e)\"] < lower_bound) | (group[\"Total GHG Emissions (Metric Tons CO2e)\"] > upper_bound)\n",
    "median_value = group[\"Total GHG Emissions (Metric Tons CO2e)\"].median()\n",
    "data_clean1.loc[outliers.index, \"Total GHG Emissions (Metric Tons CO2e)\"] = median_value # Filtering detected outliers with median value\n",
    "\n",
    "eui_trend = data_clean1.groupby(\"Year Ending\")[\"Site EUI (GJ/m²)\"].mean()\n",
    "# Time Series Analysis\n",
    "plt.figure(figsize=(12,6)) \n",
    "plt.plot(eui_trend.index, eui_trend.values, color='blue')\n",
    "plt.title(\"Yearly Trend of Average Site EUI (GJ/m²)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Site EUI (GJ/m²)\")\n",
    "plt.xticks(ticks=eui_trend.index, labels=eui_trend.index.astype(int))\n",
    "plt.show()\n",
    "\n",
    "top_10 = data_clean1.groupby(['Property Id', 'Property Name'])[\"Total GHG Emissions (Metric Tons CO2e)\"].sum().sort_values(ascending=False).head(10).reset_index() #Filtering top 10 highest GHG emissions by property name\n",
    "# Bar Chart\n",
    "figure, ax = plt.subplots()\n",
    "bars = ax.bar(top_10['Property Name'], top_10[\"Total GHG Emissions (Metric Tons CO2e)\"]) \n",
    "plt.title(\"Top 10 Buildings with Highest GHG Emissions\")\n",
    "plt.xlabel(\"Building Name\")\n",
    "plt.ylabel(\"Total GHG Emissions (Metric Tons CO2e)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.1f}\", ha=\"center\", va=\"bottom\")\n",
    "plt.show()\n",
    "\n",
    "#Heatmap Data\n",
    "heatmap_data = data_clean1.pivot_table(index=\"Primary Property Type - Self Selected\", values=\"Site EUI (GJ/m²)\", aggfunc=\"mean\") #Utilizing a pivot table to get the proper data compiled for the heatmap\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"YlGnBu\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Heatmap of Average Site EUI (GJ/m²) by Property Type\")\n",
    "plt.xlabel(\"Property Type\")\n",
    "plt.ylabel(\"Average Site EUI (GJ/m²)\")\n",
    "plt.show()\n",
    "#Correlation Matrix\n",
    "correlation = [\"Site Energy Use (GJ)\", \"Total GHG Emissions (Metric Tons CO2e)\", \"Property GFA - Self-Reported (m²)\"]\n",
    "corr_matrix = data_clean1[correlation].corr()\n",
    "display(corr_matrix)\n",
    "\n",
    "print(data[\"Primary Property Type - Self Selected\"].unique())\n",
    "# To use Energy Star Score column in dataset, we have to revert back to pre-dropped data as the column contained more than 40% NAN values\n",
    "office = data[data[\"Primary Property Type - Self Selected\"] == \"Office\"][\"ENERGY STAR Score\"].dropna()\n",
    "museum = data[data[\"Primary Property Type - Self Selected\"] == \"Museum\"][\"ENERGY STAR Score\"].dropna()\n",
    "\n",
    "t_stat, p_value = ttest_ind(office, museum)\n",
    "\n",
    "print(\"T-Stat:\\n\", t_stat, \"\\nP Value:\\n\", p_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
